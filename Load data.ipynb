{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tqdm\n",
    "from scipy import misc\n",
    "import pandas as pd\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt, matplotlib as mpl\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import loadData, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(loadData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls /home/tsbertalan/data2/behavioralCloning/*.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dataGenerator = loadData.DataGenerator(\n",
    "#     [\n",
    "#         os.path.join(loadData.HOME, 'data2', 'behavioralCloning', p)\n",
    "#         for p in (\n",
    "#             'data_provided.zip',\n",
    "# #             'mouseForward.zip',\n",
    "# #             'mouseReverse.zip',\n",
    "#         )\n",
    "#     ],\n",
    "#     responseKeys=('steering',),# 'throttle', 'brake',)\n",
    "# )\n",
    "# gen = dataGenerator.generate(stopOnEnd=True, epochSubsampling=.2)\n",
    "# XY = [xy for xy in tqdm.tqdm_notebook(gen)]\n",
    "# X = np.vstack([x for (x, y) in XY])\n",
    "# Y = np.vstack([y for (x, y) in XY])\n",
    "# X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del X, Y, XY, dataGenerator\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataGenerator = loadData.CenterOnlyDataGenerator(\n",
    "    [\n",
    "        os.path.join(loadData.HOME, 'data2', 'behavioralCloning', p)\n",
    "        for p in (\n",
    "            'data_provided.zip',\n",
    "            'mouseForward.zip',\n",
    "            'mouseReverse.zip',\n",
    "        )\n",
    "    ],\n",
    ")\n",
    "gen = dataGenerator.generate(stopOnEnd=True, epochSubsampling=.2)\n",
    "Y = Yunbalanced = np.vstack([y for (x, y) in tqdm.tqdm_notebook(gen)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binWidth = 2* min(np.abs(Y[Y!=0]))\n",
    "edges = []\n",
    "x = binWidth / 2\n",
    "while x < max(Y):\n",
    "    edges.append(x)\n",
    "    x += binWidth\n",
    "edges.append(x)\n",
    "\n",
    "x = -binWidth / 2\n",
    "while x > min(Y):\n",
    "    edges.append(x)\n",
    "    x -= binWidth\n",
    "edges.append(x)\n",
    "\n",
    "edges.sort()\n",
    "\n",
    "len(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist, bin_edges = np.histogram(Y, bins='auto')\n",
    "bin_edges.shape, max(hist[hist != max(hist)]) / max(hist), len(Y[Y==0]), len(Y[Y!=0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = Yunbalanced\n",
    "fig, ax = plt.subplots()\n",
    "kw = dict(bins=64, alpha=.25, normed=True)\n",
    "ax.hist(Y, label='full distribution',color='red', **kw)\n",
    "ax.hist(Y[Y!=0], label='nonzero only', color='blue', **kw)\n",
    "# ax.set_xlim(-.25, .25)\n",
    "ax.legend()\n",
    "ax.set_xlabel('turn angle')\n",
    "ax.set_ylabel('normed count');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This way produces two big spikes for the left/right cameras associated with the zero-angle rows.\n",
    "\n",
    "# class DeemphasizedZeroDataGenerator(loadData.DataGenerator):\n",
    "#     zeroKeepProbability = .07\n",
    "#     sideCameraChance = .6\n",
    "    \n",
    "#     rowsPerSample = 1\n",
    "#     def sample(self, validation=False):\n",
    "#         # Could be really inefficient; we read 3*n images, where n depends on the number of failed draws!\n",
    "#         # In practice, though, we don't seem to fail too much.\n",
    "#         p = lambda: random.uniform(0, 1)\n",
    "#         while True:\n",
    "#             X, Y = super().sample(validation=validation)\n",
    "#             if p() < self.sideCameraChance:\n",
    "#                 i = random.choice([0, 2])\n",
    "#                 x, y = X[i], Y[i]\n",
    "#                 break\n",
    "#             elif p() < self.zeroKeepProbability:\n",
    "#                 x, y = X[1], Y[1]\n",
    "#                 break\n",
    "#         return x.reshape((1, *x.shape)), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "_LCR = ('left', 'center', 'right')\n",
    "\n",
    "class DeemphasizedZeroDataGenerator(loadData.DataGenerator):\n",
    "    zeroKeepProbability = .07\n",
    "    \n",
    "    def sampleRow(self, validation=False):\n",
    "\n",
    "        while True:\n",
    "            # Get the index and increment the state.\n",
    "            indices = self._indices[validation]\n",
    "            state = self._state[validation]\n",
    "            j = indices[state]\n",
    "\n",
    "            # Reset or increment the counter.\n",
    "            if self._state[validation] == len(indices) - 1:\n",
    "                self._state[validation] = 0\n",
    "            else:\n",
    "                self._state[validation] += 1\n",
    "\n",
    "            # Get the left, center, and right image paths\n",
    "            # and corresponding requested response variables.\n",
    "            lcrImagePaths = [self.log.at[j, key] for key in _LCR]\n",
    "            response = np.array([self.log.at[j, key] for key in self.responseKeys])\n",
    "            \n",
    "            # Check for acceptable steering angle.\n",
    "            if response[0] != 0 or random.uniform(0, 1) < self.zeroKeepProbability:\n",
    "                break\n",
    "            \n",
    "        return lcrImagePaths, response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = os.path.join(loadData.HOME, 'data2', 'behavioralCloning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataGenerator = DeemphasizedZeroDataGenerator(\n",
    "    os.path.join(datadir, 'data_provided.zip')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = Ybalanced = np.vstack([dataGenerator.sample()[1] for _ in tqdm.tqdm_notebook(range(3000))])\n",
    "Y[Y==0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "kw = dict(bins=64, alpha=.25, normed=True)\n",
    "ubN, ubBins, ubPatches = ax.hist(Yunbalanced, label='full distribution', color='red', **kw)\n",
    "ubPatches[0].set_label('full distribution\\n(max normed count is %.3g)' % max(ubN))\n",
    "ax.hist(Ybalanced, label='zero-centered kept w.p. %s' % dataGenerator.zeroKeepProbability, color='blue', **kw)\n",
    "# ax.set_xlim(-.25, .25)\n",
    "# ax.set_ylim(0, 4)\n",
    "ax.legend(fontsize=12, loc='right')\n",
    "ax.set_xlabel('turn angle [rad]')\n",
    "ax.set_ylabel('normed count');\n",
    "fig.savefig('doc/zeroCenteredKeptWP%s.png' % str(dataGenerator.zeroKeepProbability).replace('.', 'p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import models, nnUtils\n",
    "Model = models.Nvidia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "modelname = 'deemphasizedZeroLR-mouse-kl2p0001'\n",
    "kernel_regularizer = keras.regularizers.l2(0.0001)\n",
    "#bias_regularizer = keras.regularizers.l2(0.01)\n",
    "\n",
    "model = modelReg = Model(\n",
    "    1, dataGenerator.sampleImageShape,\n",
    "    optimizer=keras.optimizers.Nadam(\n",
    "        lr=0.0001, #beta_1=0.9, beta_2=0.999, epsilon=1e-08, schedule_decay=0.004)\n",
    "    ),\n",
    "    kernel_regularizer=kernel_regularizer,\n",
    "    #bias_regularizer=bias_regularizer,\n",
    ")\n",
    "\n",
    "trainGen = dataGenerator.generate(epochSubsampling=1.0)\n",
    "validGen = dataGenerator.generate(validation=True)\n",
    "\n",
    "history = nnUtils.fitModelWithDataGenerator(model, dataGenerator, modelname, epochs=epochs)\n",
    "\n",
    "fpath = os.path.join(datadir, '%s.h5' % modelname)\n",
    "print('Saving to', fpath)\n",
    "model.save(fpath)\n",
    "\n",
    "trainIndices, validationIndices = dataGenerator._indices\n",
    "for ind, lab in zip(dataGenerator._indices, ('train', 'validation')):\n",
    "    \n",
    "    imgs = []\n",
    "    responses = []\n",
    "    for k in range(ind[0], ind[0]+1000):\n",
    "        try:\n",
    "            image, response = dataGenerator.getImageResponse(k)\n",
    "            imgs.append(image.reshape((1, *image.shape)))\n",
    "            responses.append(response)\n",
    "        except KeyError:\n",
    "            break\n",
    "    X = np.vstack(imgs)\n",
    "    Y = np.vstack(responses)\n",
    "\n",
    "    pred = model.predict(X)\n",
    "    pred.shape, Y.shape\n",
    "\n",
    "    from collections import deque\n",
    "    def runningMean(x, N):\n",
    "        y = []\n",
    "        hist = deque(maxlen=N)\n",
    "        for a in x:\n",
    "            hist.append(a)\n",
    "            y.append(np.mean(hist))\n",
    "        return np.array(y)\n",
    "    \n",
    "    ind = np.copy(ind)\n",
    "    ind.sort()\n",
    "    fig, ax = plt.subplots()\n",
    "    start = 0\n",
    "    end = start + 200\n",
    "    ax.plot(Y[start:end], label=r'truth $\\theta$', color='black')\n",
    "    ax.plot(pred[start:end], label=r'predictions $\\hat\\theta$', color='red')\n",
    "    filtersize = 3\n",
    "    scale = 1\n",
    "    smoothed = scale * runningMean(pred, filtersize)\n",
    "    ax.plot(\n",
    "        smoothed[start:end], \n",
    "        label=r'$\\hat\\rho = %.1f \\cdot box_{%d}(\\hat\\theta)$' % (scale, filtersize),\n",
    "        alpha=.25,\n",
    "        color='red',\n",
    "    )\n",
    "    ax.set_xlabel('time [samples]')\n",
    "    ax.set_ylabel('angle [radians]')\n",
    "    ax.set_title(lab)\n",
    "    ax.legend();\n",
    "    fig.savefig('doc/smoothingEffect-%s-%s.png' % (modelname, lab))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
