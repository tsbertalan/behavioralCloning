{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras, numpy as np, matplotlib as mpl, matplotlib.pyplot as plt, tqdm\n",
    "import os.path\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nnUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn, sklearn.model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = os.path.join(os.path.expanduser('~'), 'data2', 'behavioralCloning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = np.load(os.path.join(datadir, 'multiData-mouseForwardFuller.npz'))\n",
    "# X = data['X']\n",
    "# Y = data['Y'][:, 0].reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ~/data2/behavioralCloning/*.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import loadData, models\n",
    "\n",
    "from importlib import reload\n",
    "reload(loadData);\n",
    "reload(models);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataGenerator = loadData.DeemphasizedZeroDataGenerator(\n",
    "    [\n",
    "        os.path.join(loadData.HOME, 'data2', 'behavioralCloning', p)\n",
    "        for p in (\n",
    "#             'data_provided.zip',\n",
    "            'mouseForward.zip',\n",
    "            'mouseReverse.zip',\n",
    "            'longCarefulForward.zip',\n",
    "            'longCarefulReverse.zip',\n",
    "#             'dirtSidesForward.zip',\n",
    "#             'dirtSidesReverse.zip',\n",
    "#             'data_provided.zip',\n",
    "        )\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEPOCH = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_regularizer = keras.regularizers.l2(0.0001)\n",
    "#bias_regularizer = keras.regularizers.l2(0.01)\n",
    "\n",
    "modelname = ('deemZero-mouseLongCare-kl2%.1g-%depoch-fulldata' % (\n",
    "    kernel_regularizer.l2, NEPOCH\n",
    ")).replace('0.', 'p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "Model = models.Nvidia\n",
    "\n",
    "model = Model(\n",
    "    1, dataGenerator.sampleImageShape,\n",
    "    optimizer=keras.optimizers.Nadam(\n",
    "        lr=0.0001, #beta_1=0.9, beta_2=0.999, epsilon=1e-08, schedule_decay=0.004)\n",
    "    ),\n",
    "    #kernel_regularizer=kernel_regularizer,\n",
    "    #bias_regularizer=bias_regularizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "trainGen = dataGenerator.generate(epochSubsampling=1)\n",
    "validGen = dataGenerator.generate(validation=True)\n",
    "history = nnUtils.fitModelWithDataGenerator(model, dataGenerator, modelname, epochs=NEPOCH, max_queue_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fpath = os.path.join(datadir, '%s.h5' % modelname)\n",
    "print('Saving to', fpath)\n",
    "model.save(fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!recent /home/tsbertalan/data2/behavioralCloning/ | head -n 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(loadData)\n",
    "\n",
    "trainIndices, validationIndices = dataGenerator._indices\n",
    "for ind, lab in zip(dataGenerator._indices, ('train', 'validation')):\n",
    "    \n",
    "    imgs = []\n",
    "    responses = []\n",
    "    for k in range(ind[0], ind[0]+1000):\n",
    "        try:\n",
    "            image, response = dataGenerator.getImageResponse(k)\n",
    "            imgs.append(image.reshape((1, *image.shape)))\n",
    "            responses.append(response)\n",
    "        except KeyError:\n",
    "            break\n",
    "    X = np.vstack(imgs)\n",
    "    Y = np.vstack(responses)\n",
    "\n",
    "    pred = model.predict(X)\n",
    "    pred.shape, Y.shape\n",
    "\n",
    "    from collections import deque\n",
    "    def runningMean(x, N):\n",
    "        y = []\n",
    "        hist = deque(maxlen=N)\n",
    "        for a in x:\n",
    "            hist.append(a)\n",
    "            y.append(np.mean(hist))\n",
    "        return np.array(y)\n",
    "    \n",
    "    ind = np.copy(ind)\n",
    "    ind.sort()\n",
    "    fig, ax = plt.subplots()\n",
    "    if lab == 'train':\n",
    "        start = 580\n",
    "        end = start + 160\n",
    "    else:\n",
    "        start = 243\n",
    "        end = start + 60\n",
    "    samples = range(start, end)\n",
    "    \n",
    "    ax.plot(samples, Y[start:end], label=r'truth $\\theta$', color='black')\n",
    "    ax.plot(\n",
    "        samples, \n",
    "        pred[start:end],\n",
    "        label=r'predictions $\\hat\\theta$', color='magenta',\n",
    "        #s=10,\n",
    "    )\n",
    "    filtersize = 6\n",
    "    scale = 1\n",
    "    smoothed = scale * runningMean(pred, filtersize)\n",
    "    ax.plot(\n",
    "        samples, smoothed[start:end], \n",
    "        label=r'$\\hat\\rho = %.1f \\cdot box_{%d}(\\hat\\theta)$' % (scale, filtersize),\n",
    "        #alpha=.5,\n",
    "        color='green',\n",
    "    )\n",
    "    \n",
    "    # Add some insets of the input.\n",
    "    ninset =6\n",
    "    w = h = 1./(ninset+2)\n",
    "    for xloc, i in zip(\n",
    "        np.linspace(w, 1-2*w, ninset),\n",
    "        np.linspace(start, end-1, ninset).astype(int)\n",
    "    ):\n",
    "        l = xloc; b = .1100\n",
    "        inset = fig.add_axes([l, b, w, h])\n",
    "        loadData.showxy(\n",
    "            X[i], Y[i], y2=pred[i], ax=inset, \n",
    "            l1kwargs=dict(color='white', linewidth=2), l2kwargs=dict(color='magenta', linewidth=2, alpha=.5)\n",
    "        )\n",
    "        inset.set_title(\n",
    "            '$t=%d$' % samples[i-start]\n",
    "#             + '\\n' + \n",
    "#             r'$\\theta=%.2g$' % (Y[i],)\n",
    "#             + '\\n' +\n",
    "#             r'$\\hat\\theta=%.2g$' % (pred[i],),\n",
    "            ,fontsize=10,\n",
    "        )\n",
    "    \n",
    "    ax.set_xlabel('time [samples]')\n",
    "    ax.set_ylabel('angle [radians]')\n",
    "    ax.set_title(lab)\n",
    "    ax.legend(loc='upper left');\n",
    "    fig.savefig('doc/smoothingEffect-%s-%s.png' % (modelname, lab))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
